<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} }); </script>

# 框架开发实践

除了OpenAI SDK和其他基础库之外，不依赖其他的重型库。除了核心的Agent类，一切皆为Tools。在许多其他框架中需要独立学习的**Memory**（记忆）、**RAG**（检索增强生成）、**RL**（强化学习）、**MCP**（协议）等模块，都被统一抽象为一种“工具”。

这种设计的初衷是消除不必要的抽象层，让学习者可以回归到最直观的“智能体调用工具”这一核心逻辑上，从而真正实现快速上手和深入理解的统一。

整个框架概览：
```
hello_agents/
├── core/                          # 核心模块
│   ├── agent.py                   # Agent基础类（定义Agent接口和基础行为）
│   ├── config.py                  # 配置管理（全局配置和参数管理）
│   ├── database_config.py         # 数据库配置（数据库连接和配置管理）
│   ├── exceptions.py              # 异常定义（自定义异常类）
│   ├── llm.py                     # LLM接口（大语言模型调用封装）
│   └── message.py                 # 消息定义（消息格式和类型定义）
│
├── agents/                        # Agent实现模块
│   ├── simple_agent.py            # 简单Agent（基础对话Agent）
│   ├── react_agent.py             # ReAct Agent（推理-行动循环Agent）
│   ├── plan_solve_agent.py        # 计划求解Agent（规划执行Agent）
│   └── reflection_agent.py        # 反思Agent（自我反思改进Agent）
│
├── memory/                        # 记忆系统模块
│   ├── base.py                    # 基础数据结构（MemoryItem, MemoryConfig, BaseMemory）
│   ├── manager.py                 # 记忆管理器（统一协调调度）
│   ├── embedding.py               # 统一嵌入服务（DashScope/Local/TFIDF）
│   ├── types/                     # 记忆类型实现
│   │   ├── working.py             # 工作记忆（TTL管理，纯内存）
│   │   ├── episodic.py            # 情景记忆（事件序列，SQLite+Qdrant）
│   │   ├── semantic.py            # 语义记忆（知识图谱，Qdrant+Neo4j）
│   │   └── perceptual.py          # 感知记忆（多模态，SQLite+Qdrant）
│   ├── storage/                   # 存储后端实现
│   │   ├── qdrant_store.py        # Qdrant向量存储（高性能向量检索）
│   │   ├── neo4j_store.py         # Neo4j图存储（知识图谱管理）
│   │   └── document_store.py      # SQLite文档存储（结构化持久化）
│   └── rag/                       # RAG系统
│       ├── pipeline.py            # RAG管道（端到端处理）
│       └── document.py            # 文档处理器（多格式解析）
│
├── context/                        # 上下文模块
│   ├── builder.py                    # 构建器实现GSSC流水线
│
├── tools/                         # 工具系统模块
│   ├── base.py                    # 工具基类（定义Tool接口）
│   ├── registry.py                # 工具注册表（工具管理和发现）
│   ├── chain.py                   # 工具链（工具组合和编排）
│   ├── async_executor.py          # 异步执行器（并发工具调用）
│   └── builtin/                   # 内置工具集
│       ├── memory_tool.py         # 记忆工具（Agent记忆能力）
│       ├── rag_tool.py            # RAG工具（智能问答能力）
│       ├── search.py              # 搜索工具（网络搜索能力）
│       ├── calculator.py          # 计算器工具（数学计算能力）
│       ├── terminal_tool.py       # 终端工具（命令行执行能力）
│       ├── note_tool.py           # 笔记工具（笔记记录能力）
│       ├── mcp_wrapper_tool.py    # MCP包装工具（MCP协议工具封装）
│       ├── protocol_tools.py      # 协议工具（多协议支持）
│       ├── bfcl_evaluation_tool.py # BFCL评估工具（Berkeley Function Calling评估）
│       ├── gaia_evaluation_tool.py # GAIA评估工具（通用AI助手评估）
│       ├── llm_judge_tool.py      # LLM评判工具（模型评判能力）
│       ├── win_rate_tool.py       # 胜率工具（对战评估工具）
│       └── rl_training_tool.py    # RL训练工具（强化学习训练）
│
├── protocols/                     # 协议模块
│   ├── base.py                    # 协议基类（定义Protocol接口）
│   ├── mcp/                       # Model Context Protocol
│   │   ├── client.py              # MCP客户端（协议客户端实现）
│   │   ├── server.py              # MCP服务器（协议服务端实现）
│   │   └── utils.py               # MCP工具函数（辅助工具）
│   ├── a2a/                       # Agent-to-Agent Protocol
│   │   └── implementation.py      # A2A实现（Agent间通信协议）
│   └── anp/                       # Agent Negotiation Protocol
│       └── implementation.py      # ANP实现（Agent协商协议）
│
├── rl/                            # 强化学习模块
│   ├── datasets.py                # 数据集处理（训练数据管理）
│   ├── rewards.py                 # 奖励函数（定义奖励机制）
│   ├── trainers.py                # 训练器（RL训练逻辑）
│   └── utils.py                   # RL工具函数（辅助功能）
│
└── evaluation/                    # 评估模块
    └── benchmarks/                # 基准测试集
        ├── bfcl/                  # Berkeley Function Calling Leaderboard
        │   ├── bfcl_integration.py # BFCL集成（集成测试）
        │   ├── dataset.py         # 数据集加载（BFCL数据）
        │   ├── evaluator.py       # 评估器（评估逻辑）
        │   └── metrics.py         # 评估指标（性能指标）
        ├── gaia/                  # GAIA Benchmark
        │   ├── dataset.py         # 数据集加载（GAIA数据）
        │   ├── evaluator.py       # 评估器（评估逻辑）
        │   └── metrics.py         # 评估指标（性能指标）
        └── data_generation/       # 数据生成模块
            ├── dataset.py         # 数据集生成（合成数据）
            ├── llm_judge.py       # LLM评判（模型评判）
            └── win_rate.py        # 胜率计算（对战评估）
```


|部分|内容|描述|
|:---:|:---:|:---:|
|[core](#core)|LLM接口封装 Message数据类，agent抽象基类|最核心的部分，骨架|
|[Agents](#agents)|simpleagent reactagent reflecagent plansolveagent|内置实现的几种agent范式|
|[Tool](#tool)|Tool抽象基类 Toolparameter参数类 Registry注册机制 Toolchain工具链 |工具的系统定义|
|内置工具集|Memory&RAG Context protocols||
|[Memory](#memory)|Working Episodic Semantic Perceptual|几种记忆类型，需要嵌入和数据库服务|
|[RAG](#rag)|格式转换 嵌入 MQE HyDE检索|将多种数据通过向量存储并支持向量检索|
|[Context](#context-上下文工程)|ContextBuilder NoteTool TerminalTool|上下文构建方法，笔记工具，文件系统工具|
|[protocols](#protocol)|MCP A2A ANP|主流智能体通信协议，还可以自己构建服务|
|[agentic-RL](#agentic-rl)|SFT&GRPO实战 概念理清|SFT数据格式，GRPO奖励设计，将LLMAgent当作强化学习中的策略 $\pi$ 与环境交互|

## core

核心层要实现LLM的接口封装，并且定义智能体与LLM交互的消息类Message。

agent抽象基类定义agent的通用方法，主要方法为run方法，决定agent的执行逻辑。

## Agents

几个经典范式的Agent：

* **SimpleAgent**： 简单调用工具回答问题
* **reactagent**： 思考-行动-观察范式（需要调用工具）
* **reflectagent**：反馈-改进范式（未加入工具）
* **plansolveagent**： 规划和解决agent（未加入工具）

## Tool

* Toolparameter参数类则定义参数的形式，要包含描述、类型等信息。

* Tool的抽象基类，要有运行和获得工具描述俩个方法。工具描述需要提供给大模型。

* Registry注册机制是工具的管理中枢，需要提供工具的注册、发现、执行等核心功能

* Toolchain工具链用于需要链式调用的工具串，同样需要工具类和注册机制。


<div align='center'>
<img src="../images/c3/memoryrag.png" alt="memoryrag" width="400">
<p><strong>Memory和RAG架构</strong></p>
</div>


## Memory

<div align='center'>
<img src="../images/c3/memory.png" alt="memory" width="400">
</div>

**接口设计**：MemoryTool-MemoryManager-Memorytypes[working episodic...]

记忆系统最终还是一个tool工具，先从最顶层的MemoryTool，即用户能看到并使用的部分开始分析结构。

* **MemoryTool**: 支持的功能：add，search，forget，consolidate

    add：添加记忆到不同类型记忆中
    search：从不同类型记忆中搜索query相关记忆
    forget：基于多种策略遗忘记忆（基于重要性、基于时间、基于容量）
    consolidate： 整合记忆，将重要的短期记忆提升为长期记忆

* **MemoryManager**:这一层负责管理不同的记忆模块，提供统一的操作接口


### **Memorytypes**:

HelloAgents记忆系统
├── 基础设施层 (Infrastructure Layer)
│   ├── MemoryManager - 记忆管理器（统一调度和协调）
│   ├── MemoryItem - 记忆数据结构（标准化记忆项）
│   ├── MemoryConfig - 配置管理（系统参数设置）
│   └── BaseMemory - 记忆基类（通用接口定义）
├── 记忆类型层 (Memory Types Layer)
│   ├── WorkingMemory - 工作记忆（临时信息，TTL管理）
│   ├── EpisodicMemory - 情景记忆（具体事件，时间序列）
│   ├── SemanticMemory - 语义记忆（抽象知识，图谱关系）
│   └── PerceptualMemory - 感知记忆（多模态数据）
├── 存储后端层 (Storage Backend Layer)
│   ├── QdrantVectorStore - 向量存储（高性能语义检索）
│   ├── Neo4jGraphStore - 图存储（知识图谱管理）
│   └── SQLiteDocumentStore - 文档存储（结构化持久化）
└── 嵌入服务层 (Embedding Service Layer)
    ├── DashScopeEmbedding - 通义千问嵌入（云端API）
    ├── LocalTransformerEmbedding - 本地嵌入（离线部署）
    └── TFIDFEmbedding - TFIDF嵌入（轻量级兜底）

1. **WorkingMemory（工作记忆）**

**数据结构**：工作记忆使用`MemoryItem`基础结构，包含id（唯一标识符）、content（记忆内容文本）、user_id（用户标识）、timestamp（时间戳）、importance（重要性分数0-1）、metadata（元数据字典）。内部维护优先级堆结构`(priority, timestamp, memory_item)`用于快速访问高优先级记忆。

**存储方式**：采用纯内存存储，不涉及持久化。主存储使用Python列表`self.memories`，优先级管理使用heapq堆结构`self.memory_heap`，同时维护Token计数器追踪当前内存使用量。

**检索机制**：采用混合检索策略，分两步执行。第一步是语义检索，使用TF-IDF向量化进行文本相似度计算，采用scikit-learn的`cosine_similarity`计算查询与记忆的余弦相似度，若TF-IDF失败则自动降级到关键词匹配。第二步是评分排序，基础相关性 = 向量分数×0.7 + 关键词分数×0.3，时间衰减因子每6小时按`decay_factor`指数衰减（最小保留10%），重要性权重 = 0.8 + importance×0.4，最终分数 = （基础相关性×时间衰减）×重要性权重。

**遗忘机制**：采用多策略硬删除。TTL自动过期具有最高优先级，默认120分钟超时自动删除，每次检索/添加时触发惰性清理。支持三种遗忘策略：importance_based删除importance低于阈值（默认0.1）的记忆、time_based删除超过max_age_days的记忆、capacity_based在超出max_capacity时删除最低优先级记忆（优先级 = importance × 时间衰减因子）。

---

2. **EpisodicMemory（情景记忆）**

**数据结构**：使用`Episode`类扩展`MemoryItem`，增加episode_id（情景唯一标识）、session_id（会话标识，用于关联同一会话的多个事件）、context（上下文信息字典）、outcome（事件结果）、participants（参与者列表）、tags（标签列表）等字段。

**存储方式**：采用SQLite + Qdrant混合存储架构。SQLite作为权威存储，存储完整的结构化数据，支持复杂的SQL查询和过滤，字段包含memory_id、user_id、content、memory_type、timestamp、importance、properties。Qdrant作为向量索引，存储文本嵌入向量（统一使用sentence-transformers，默认384维），元数据包含memory_id、user_id、memory_type、importance、session_id，用于快速语义检索。同时维护内存缓存，包括`episodes`列表和`sessions`字典用于快速访问。

**检索机制**：采用多阶段检索流程。阶段1是结构化过滤，使用SQLite按time_range、importance_threshold预筛选候选集，通过SQL查询高效过滤。阶段2是语义检索，对查询文本进行向量化，使用Qdrant的余弦相似度检索top-K候选，与结构化过滤结果求交集。阶段3是重排序，综合考虑向量相似度（40%权重）、时间新鲜度（指数衰减，最近7天内线性提升至2.0倍）、重要性加权（0.8 + importance×0.4）、关键词匹配加成（命中查询词额外+0.1），最终分数 = (相似度×0.4 + 新鲜度×0.3 + 重要性×0.3) + 关键词加成。若向量检索无结果，使用内存缓存的简单关键词匹配作为回退机制。

**遗忘机制**：支持三种策略的硬删除，包括importance_based删除importance < threshold的记忆、time_based删除超过max_age_days的记忆、capacity_based在超出容量时删除最低优先级记忆。删除操作同步清理内存缓存（episodes列表）、SQLite数据库记录和Qdrant向量索引。

---

3. **SemanticMemory（语义记忆）**

**数据结构**：分为三层结构。记忆层使用基础`MemoryItem`结构。实体层（Entity）包含entity_id、name、entity_type（PERSON/ORG/PRODUCT/SKILL/CONCEPT等）、description、properties、frequency（出现频率），由spaCy NLP模型自动提取。关系层（Relation）包含from_entity、to_entity、relation_type、strength（关系强度）、evidence（支持证据）、frequency（关系出现频率）。

**存储方式**：采用Qdrant + Neo4j双数据库架构。Qdrant作为向量存储，存储文本嵌入向量，元数据包含memory_id、user_id、memory_type、importance、entity_ids。Neo4j作为图数据库，存储实体节点（Entity）包含entity_id、name、type、frequency等属性，存储关系边（Relation）包含type、strength、frequency等属性，支持Cypher查询进行图遍历和关系推理，同时存储词法分析结果（词性、依存关系等语言学特征）。内存缓存维护entities字典（entity_id -> Entity）、relations列表（Relation对象列表）、semantic_memories列表（MemoryItem对象列表）。

**检索机制**：采用混合检索策略（向量+图+推理）。步骤1是向量检索，对查询文本向量化，使用Qdrant的余弦相似度检索top-K候选，筛选向量分数>0.3的结果。步骤2是图检索，从查询文本提取实体（spaCy NER），执行多跳图遍历（1-2跳），查询包含相关实体的记忆节点，计算图相关性分数（实体匹配度+关系强度）。步骤3是混合排序，对内容去重（相同content只保留最高分），向量分数权重60%、图分数权重40%，重要性辅助排序，最小相关性阈值0.1。系统支持语言智能，自动检测中文/英文（按字符比例判断），动态选择spaCy模型（zh_core_web_sm / en_core_web_sm），支持多语言实体识别和词法分析。

**遗忘机制**：支持三种策略的硬删除，包括importance_based删除低重要性记忆、time_based删除过期记忆、capacity_based在超容量时删除低优先级记忆。删除操作级联清理内存缓存（memories/entities/relations）、Qdrant向量索引、Neo4j图节点和关系、以及关联的词法分析结果。

---

4. **PerceptualMemory（感知记忆）**

**数据结构**：使用`Perception`类扩展存储，包含perception_id（感知数据唯一标识）、data（原始数据，可以是文本/图像字节/音频等）、modality（模态类型：text/image/audio/video/structured）、encoding（编码向量）、data_hash（数据哈希值，用于去重）、metadata（扩展元数据）。

**存储方式**：采用多模态分离存储（SQLite + 多个Qdrant集合）。SQLite作为权威文档存储，存储完整的记忆项和元数据，包含perception_id、modality、context、tags等。Qdrant按模态分集合存储，text集合384维（sentence-transformers）、image集合512维（CLIP模型）或降级为384维哈希向量、audio集合512维（CLAP模型）或降级为384维哈希向量，每个模态独立集合避免维度冲突。编码策略为文本使用sentence-transformers多语言模型、图像优先CLIP降级为确定性哈希向量（PIL特征哈希）、音频优先CLAP降级为音频特征哈希、其他类型字符串序列化后哈希。

**检索机制**：采用同模态语义检索（跨模态受限）。步骤1是向量检索，识别查询模态和目标模态，若同模态则使用对应Qdrant集合进行余弦相似度检索，若跨模态则受限于CLIP/CLAP依赖当前回退到简单匹配。步骤2是融合排序，综合考虑向量相似度（基础分）、时间新鲜度（7天内指数提升）、重要性加权（0.8 + importance×0.4），最终分数 = (相似度×时间衰减) × 重要性权重。若向量检索无结果，使用SQLite结构化过滤+关键词匹配作为回退机制。

**遗忘机制**：支持三种策略的硬删除，包括importance_based删除低重要性感知数据、time_based删除过期感知记忆、capacity_based在超容量时删除最低优先级。删除操作同步清理内存缓存（perceptions/perceptual_memories）、SQLite文档库、所有模态的Qdrant向量集合、以及模态索引（modality_index）。

---


四种记忆系统各有侧重：WorkingMemory轻量、快速、短生命周期，适合会话上下文；EpisodicMemory双存储保证可靠性，平衡检索速度和查询灵活性；SemanticMemory深度语义理解，支持复杂推理和知识关联；PerceptualMemory多模态支持，分离存储避免维度冲突。所有记忆类型均采用硬删除遗忘机制而非软标记，确保资源及时释放。检索均采用混合策略，在语义理解和精确匹配之间取得平衡。


## RAG


<div align='center'>
<img src="../images/c3/rag.png" alt="rag" width="400">
</div>


HelloAgents RAG系统
├── 用户层 RAGTool统一接口
├── 文档处理层 (Document Processing Layer)
│   ├── DocumentProcessor - 文档处理器（多格式解析）
│   ├── Document - 文档对象（元数据管理）
│   └── Pipeline - RAG管道（端到端处理）
├── 嵌入表示层 (Embedding Layer)
│   └── 统一嵌入接口 - 复用记忆系统的嵌入服务
├── 向量存储层 (Vector Storage Layer)
│   └── QdrantVectorStore - 向量数据库（命名空间隔离）
└── 智能问答层 (Intelligent Q&A Layer)
    ├── 多策略检索 - 向量检索 + MQE + HyDE
    ├── 上下文构建 - 智能片段合并与截断
    └── LLM增强生成 - 基于上下文的准确问答

### 处理pipeline

```
任意格式文档 → MarkItDown转换 → Markdown文本 → 智能分块 → 向量化 → 存储检索
```

1. **多模态文档载入**

使用微软开源的`MarkItDown`作为统一的文档转换引擎，无论输入时PDF、word、Excel、图片还是音频，最终都会转换为标准的Markdown格式。

2. **智能分块策略**

```
标准Markdown文本 → 标题层次解析 → 段落语义分割 → Token计算分块 → 重叠策略优化 → 向量化准备
       ↓                ↓              ↓            ↓           ↓            ↓
   统一格式          #/##/###        语义边界      大小控制     信息连续性    嵌入向量
   结构清晰          层次识别        完整性保证    检索优化     上下文保持    相似度匹配
```

3. **统一嵌入和向量存储**

实现统一嵌入接口，使用顺序：API向量化->本地嵌入模型->TF-IDF兜底，向量存入Qdrant数据库中

### 高级检索策略

三种互补的高级检索策略：**多查询扩展MQE、假设文档嵌入HyDE**

1. **多查询扩展MQE**

Multi-Query Expansion 通过生成语义等价的多样化查询来提高检索召回率的技术。使用LLM让它把一句话的表述扩展一下，例如，"如何学习Python"可以扩展为"Python入门教程"、"Python学习方法"、"Python编程指南"等多个查询。

```
prompt = [
            {"role": "system", "content": "你是检索查询扩展助手。生成语义等价或互补的多样化查询。使用中文，简短，避免标点。"},
            {"role": "user", "content": f"原始查询：{query}\n请给出{n}个不同表述的查询，每行一个。"}
        ]
```


2. **假设文档嵌入HyDE**

Hypothetical Document Embedding 核心思想时用答案找答案。让LLM先生成一个假设性的答案段落，然后用这个段落去检索真实文档。

```
prompt = [
            {"role": "system", "content": "根据用户问题，先写一段可能的答案性段落，用于向量检索的查询文档（不要分析过程）。"},
            {"role": "user", "content": f"问题：{query}\n请直接写一段中等长度、客观、包含关键术语的段落。"}
        ]
```

3. **扩展检索框架**

将MQE和HyDE整合到一起，核心机制为“扩展-检索-合并”。系统根据原始查询生成多个扩展查询（MQE和HyDE结果）；然后对每个扩展查询执行向量搜索，获得候选文档池；最后，对文档池查重和分数排序，返回最相关的top-k文档

实际应用中，这三种策略的组合使用效果最佳。MQE擅长处理用词多样性问题，HyDE擅长处理语义鸿沟问题，而统一框架则确保了结果的质量和多样性。对于一般查询，建议启用MQE；对于专业领域查询，建议同时启用MQE和HyDE；对于性能敏感场景，可以只使用基础检索或仅启用MQE。


<div align='center'>
<img src="../images/c3/总结.png" alt="总结" width="400">
</div>



## Context 上下文工程

Transformer让每个token能够与上下文中的所有token简历关联，理论上形成n^2级别的俩俩注意力关系，但是随着上下文长度增长，这种关系将被减弱。模型的注意力模式也来自于训练数据分布-短序列比长序列更常见，虽然位置编码如ROPE插值等可将长度外推，但不可避免的会牺牲位置精度。

上下文工程关注的是，在每一次模型调用前，如何以可复用、可度量、可演进的方式，拼装优化输入上下文，从而提升正确性、鲁棒性和效率。

压缩整合：
结构化笔记：
子代理架构：

### ContextBUilder

1. **上下文模板格式**：

* `[Role & Polices]` : 明确 Agent 角色定位和行为准则
* `[Task]` : 当前需要完成的具体任务
* `[State]` : Agent的当前状态和上下文信息
* `[Evidence]` : 从外部知识库检索的证据信息
* `[Context]` : 历史对话和相关记忆 
* `[Output]` :期望输出的格式和要求

2. **GSSC流水线**

GSSC(Gather-Select-Structure-Compress)，将上下文过程分解为四个清晰的阶段。

* Gather：从多个来源汇集候选信息，例如对话历史，RAG内容，记忆内容。

* Select：根据相关性和新近性对候选信息进行评分和选择，是流水线的核心。

* Structure：将选中的信息组织为结构化的上下文模板

* Compress：对超限上下文进行压缩处理

### NoteTool

NoteTool是为长时程任务提供的**结构化外部记忆组件**，以Markdown文件作为载体，头部使用YAML前置元数据记录关键信息，正文用于记录状态、结论、阻塞和行动项等内容。

一个NoteTool组件包含create、read、update、search、list、summary、delete等操作，完成整个生命周期。**NoteTool可以与ContexBuilder集成，将笔记内容构建进上下文中。**

### TerminalTool

Terminal（即时文件系统访问）为智能体提供安全的**命令行执行能力**，支持常用的文件系统和文本处理命令，并通过多层安全机制确保系统安全。

TerminalTool应该支持：代码库探索、日志文件分析、数据文件预览等功能。同时还需要安全机制可通过命令白名单、工作目录限制、超时控制、输出大小限制等机制，防止TerminalTool造成不可逆转的破坏。

TerminalTool可以**与MemoryTool、ContextBuilder和NoteTool协同使用**。比如查询到的信息可以放进记忆系统，放进笔记中，放进上下文中。

## Protocol

通信协议提供一套标准化的接口规范，让智能体能够以统一的方式访问各种外部服务，无需为每个服务编写专门的适配器。就像互联网的TCP/IP协议，让不同的设备能够相互通信，不需要为各种设备编写专门的通信代码。

目前业界主流的三种协议：**MCP、A2A和ANP**


1. **MCP**

MCP 官方文档：https://modelcontextprotocol.io

MCP（Model Context Protocol）不仅是一个RPC（远程过程调用）协议，更重要的是它允许智能体和工具之间共享丰富的上下文信息。例如当智能体访问一个代码仓库时，MCP服务器不仅能够提供给文件内容，还能提供代码结构、依赖关系、提交历史等上下文信息。

2. **A2A**

A2A 官方文档：https://a2a-protocol.org/latest/

A2A（Agent-to-Agent）的理念是实现智能体之间的点对点通信，在A2A网络中，每个智能体既是服务提供者，也是服务消费者，智能体可以主动发起请求，也可以响应其他智能体的请求。

3. **ANP**

ANP 官方文档：https://agent-network-protocol.com/guide/

ANP（Agent Network Protocol）是一个概念性的协议框架，核心设计理念是构建大规模智能网络的基础设施。

ANP 的设计哲学是"去中心化服务发现"。在一个包含成百上千个智能体的网络中，如何让智能体能够找到它需要的服务？如图所示，ANP 提供了服务注册、发现和路由机制，让智能体能够动态地发现网络中的其他服务，而不需要预先配置所有的连接关系。

### 通信协议架构设计

<div align='center'>
<img src="../images/c3/协议架构设计.png" alt="rag" width="400">
</div>

采用三层设计，从底层到上层分别是：协议实现层、工具封装层和智能体集成层。

#### MCP

MCP协议采用**Host、Client、Servers**三层架构设计

<div align='center'>
<img src="../images/c3/mcp.png" alt="mcp" width="400">
</div>



MCP的**三大核心能力**：Tools、Resources、Prompts

<div align='center'>
<img src="../images/c3/mcp核心能力.png" alt="mcp核心能力" width="400">
</div>

**MCP工作流程**：

<div align='center'>
<img src="../images/c3/mcp工作流程.png" alt="mcp工作流程" width="400">
</div>

完整的交互流程：用户问题 → Claude Desktop(Host) → Claude 模型分析 → 需要文件信息 → MCP Client 连接 → 文件系统 MCP Server → 执行操作 → 返回结果 → Claude 生成回答 → 显示在 Claude Desktop 上

[VS code 配置MCP教程](https://www.runoob.com/vscode/vscode-mcp-servers.html)
**MCP传输方式**：

<div align='center'>
<img src="../images/c3/mcp传输方式.png" alt="mcp传输方式" width="400">
</div>

**MCP社区生态**：

资源库：
* [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers)
* [MCP Servers Website](https://mcpservers.org/)
* [Official MCP Servers](https://github.com/modelcontextprotocol/servers)

**常用官方服务器和社区热门服务器**：

<div align='center'>
<img src="../images/c3/mcp官方服务.png" alt="mcp官方服务" width="400">
</div>
<div align='center'>
<img src="../images/c3/mcp社区服务.png" alt="mcp社区服务" width="400">
</div>

#### A2A //TODO

#### ANP //TODO

### 自定义MCP服务器并发布


可以自己构建一个MCP服务，并在[Smithery](https://smithery.ai/)中发布。


## Agentic RL

把LLM Agent当作强化学习中的策略模型，LLM Agent有与外部环境交互的能力，可以用强化学习的方法，让LLM Agent 和特定环境进行交互。

个人感觉hello-agent教程在这一章并没有体现Agentic RL的核心-与环境交互，没有了交互，其讲的东西本质还是传统的PPO-DPO-GRPO。想要全面了解可以看最近的一篇九月份的综述文章：[The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](https://arxiv.org/pdf/2509.02547)

不过对于sft和GRPO训练实践，hello-agent还是做的挺好，我们可以实践一下这个训练流程。

### sft-GRPO实战 //TODO






